{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["## deep HW4 Q3\n","## Alireza Abbasian\n","## 402200253"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T20:52:24.661351Z","iopub.status.busy":"2024-01-19T20:52:24.660707Z","iopub.status.idle":"2024-01-19T20:52:52.373123Z","shell.execute_reply":"2024-01-19T20:52:52.371940Z","shell.execute_reply.started":"2024-01-19T20:52:24.661304Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.36.0)\n","Collecting transformers\n","  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/20/0a/739426a81f7635b422fbe6cb8d1d99d1235579a6ac8024c13d743efa6847/transformers-4.36.2-py3-none-any.whl.metadata\n","  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n","Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: transformers\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.36.0\n","    Uninstalling transformers-4.36.0:\n","      Successfully uninstalled transformers-4.36.0\n","Successfully installed transformers-4.36.2\n"]}],"source":["!pip install -U transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T20:52:52.376348Z","iopub.status.busy":"2024-01-19T20:52:52.375658Z","iopub.status.idle":"2024-01-19T20:53:01.977929Z","shell.execute_reply":"2024-01-19T20:53:01.976913Z","shell.execute_reply.started":"2024-01-19T20:52:52.376313Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import numpy as np\n","\n","import torch\n","from transformers import AutoTokenizer, AutoConfig, AutoModelWithLMHead\n","from transformers import AutoTokenizer, GPT2LMHeadModel, GPT2Config\n","\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","\n","from torch.utils.data import random_split\n","\n","import random\n","\n","from transformers import AdamW\n","\n","from transformers import get_linear_schedule_with_warmup\n","\n","import time\n","import datetime\n","from tqdm import tqdm\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import os\n","\n","from transformers import TFAutoModelForCausalLM\n","\n","import re"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T20:53:01.979591Z","iopub.status.busy":"2024-01-19T20:53:01.979157Z","iopub.status.idle":"2024-01-19T20:53:03.352572Z","shell.execute_reply":"2024-01-19T20:53:03.351623Z","shell.execute_reply.started":"2024-01-19T20:53:01.979563Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d1bd00a180c474981c0d14e11c2f1c5","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/728 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a318b8a07f0f4374b8329dea6bff0bb6","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/808 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d7675077a75464faa77a61f29d5ca4e","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a370b14197a4204bddd95b3659dfc54","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/875k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"97531f23006e4d19bb3fd45bed6b5e82","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/2.75M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd30976d743a49e0a18f9a1010ebd986","version_major":2,"version_minor":0},"text/plain":["added_tokens.json:   0%|          | 0.00/14.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b0c1326c5154798ba90a1320d0dc913","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/104 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model_name_or_path = \"HooshvareLab/gpt2-fa\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(\n","    model_name_or_path,\n","    bos_token='<s>', \n","    eos_token='</s>', \n","    pad_token='<pad>',\n","    unk_token='<unk>'\n",")\n","tokenizer.add_special_tokens({\n","    \"bos_token\": '</s>',\n","    \"eos_token\": '</s>', \n","    \"pad_token\": '<pad>',\n","    \"unk_token\": '<unk>'\n","})\n","\n","config = AutoConfig.from_pretrained(\n","    model_name_or_path,\n","    bos_token_id=tokenizer(\"<s>\")[\"input_ids\"][0], \n","    eos_token_id=tokenizer(\"</s>\")[\"input_ids\"][0], \n","    pad_token_id=tokenizer(\"<pad>\")[\"input_ids\"][0],\n","    unk_token_id=tokenizer(\"<unk>\")[\"input_ids\"][0],\n",")\n","\n","tokenizer.save_pretrained(\"/content/gpt2/\")\n","config.save_pretrained(\"/content/gpt2/\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T20:53:03.354884Z","iopub.status.busy":"2024-01-19T20:53:03.354565Z","iopub.status.idle":"2024-01-19T20:53:03.439620Z","shell.execute_reply":"2024-01-19T20:53:03.438710Z","shell.execute_reply.started":"2024-01-19T20:53:03.354851Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[1002, 909, 329]\n","[31702, 21706]\n","[209]\n","[0]\n","[2]\n","[1]\n","[6]\n","[9]\n","[10537, 579, 371, 333, 944, 4485, 316, 968, 18252, 944, 324]\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(\n","    \"/content/gpt2\",\n","    bos_token='<s>', \n","    eos_token='</s>', \n","    pad_token='<pad>'\n",")\n","\n","print(tokenizer.encode(\"این کتاب است\"))\n","print(tokenizer.encode(\"علیرضا عباسیان\"))\n","print(tokenizer.encode(\"\\n\"))\n","print(tokenizer.encode(\"<s>\"))\n","print(tokenizer.encode(\"</s>\"))\n","print(tokenizer.encode(\"<pad>\"))\n","print(tokenizer.encode(\"<|startoftext|>\"))\n","print(tokenizer.encode(\"<sep>\"))\n","print(tokenizer.encode(\"مخقهلاصخهدلخشهنتالخهال\"))"]},{"cell_type":"markdown","metadata":{},"source":["22 هجا بیشتر ندارد وزن شاهنامه"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T20:53:03.441272Z","iopub.status.busy":"2024-01-19T20:53:03.440905Z","iopub.status.idle":"2024-01-19T20:53:05.813610Z","shell.execute_reply":"2024-01-19T20:53:05.812698Z","shell.execute_reply.started":"2024-01-19T20:53:03.441237Z"},"trusted":true},"outputs":[],"source":["data_path = '/kaggle/input/ferdousi/ferdousi.txt'\n","with open(data_path, 'r', encoding='utf-8') as file:\n","    lines = file.read().splitlines()\n","    \n","lines = [line.replace(\"\\n\", \"\") for line in lines]\n","\n","beyts = [lines[i] +  \"<sep>\" + lines[i+1] + \"<sep>\" for i in range(2, len(lines)-1, 2)]\n","two_beyt = ['<s>' + beyts[i] + \"<|startoftext|>\" + beyts[i+1] + '</s>' for i in range(0, len(beyts)-1, 2)]\n","\n","max_length=40\n","encodings_dict = tokenizer(two_beyt,\n","                   truncation=True,\n","                   max_length=max_length,\n","                   padding=\"max_length\")\n","input_ids = torch.tensor(encodings_dict['input_ids'])\n","attn_masks = torch.tensor(encodings_dict['attention_mask'])"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T20:53:05.814969Z","iopub.status.busy":"2024-01-19T20:53:05.814687Z","iopub.status.idle":"2024-01-19T20:53:05.858049Z","shell.execute_reply":"2024-01-19T20:53:05.857144Z","shell.execute_reply.started":"2024-01-19T20:53:05.814945Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<s>به نام خداوند جان و خرد<sep>کزین برتر اندیشه برنگذرد<sep><|startoftext|>خداوند نام و خداوند جای<sep>خداوند روزی ده رهنمای<sep></s>\n","tensor([    0,   490,   561,  6733,  1305,   293,  2964,     9,  2639,   297,\n","         3206,  6188, 29631,   383,   343,     9,     6, 12090,   595,   561,\n","          293,  6733,   798,     9, 12090,   595,  3588,   546, 11552,   450,\n","            9,     2,     1,     1,     1,     1,     1,     1,     1,     1])\n"]}],"source":["print(two_beyt[0])\n","\n","print(input_ids[0])"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T20:53:05.859276Z","iopub.status.busy":"2024-01-19T20:53:05.859032Z","iopub.status.idle":"2024-01-19T20:53:05.987066Z","shell.execute_reply":"2024-01-19T20:53:05.986130Z","shell.execute_reply.started":"2024-01-19T20:53:05.859254Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["7648\n"]}],"source":["new_vocab = set()\n","\n","for tokens in input_ids:\n","    new_vocab.update(tokens.tolist())\n","\n","new_vocab = list(new_vocab)\n","print(len(new_vocab))"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T20:53:05.988755Z","iopub.status.busy":"2024-01-19T20:53:05.988361Z","iopub.status.idle":"2024-01-19T20:53:05.995198Z","shell.execute_reply":"2024-01-19T20:53:05.994165Z","shell.execute_reply.started":"2024-01-19T20:53:05.988714Z"},"trusted":true},"outputs":[],"source":["class FerdousiDataset(Dataset):\n","    def __init__(self):\n","        self.input_ids = input_ids\n","        self.attn_masks = attn_masks\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        beyt = self.input_ids[idx]\n","        mask = self.attn_masks[idx]\n","\n","        return beyt, mask\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T20:53:05.996662Z","iopub.status.busy":"2024-01-19T20:53:05.996357Z","iopub.status.idle":"2024-01-19T20:53:06.067806Z","shell.execute_reply":"2024-01-19T20:53:06.066885Z","shell.execute_reply.started":"2024-01-19T20:53:05.996636Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["len train_dataset =  19843\n","len test_dataset =  2480\n","Train Data:\n","**********************************\n","Sample 1:\n","token id  =  tensor([    0, 41339,  1776,  1215, 11592, 16477,     9,   490,   314,   413,\n","         6482,   656, 11592, 16477,     9,     6,   799,   530, 13052,   306,\n","          430,   457, 17161,   330,     9,   479,  2167,   463,   303,  7838,\n","         3645,   330,     9,     2,     1,     1,     1,     1,     1,     1])\n","mask  =  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0])\n","**********************************\n","Sample 2:\n","token id  =  tensor([    0,  8033,   367,   449,   312,   798, 36359,     9, 15035,  8803,\n","          664,  6176, 11114,     9,     6,   968, 21463,   596,  1481,   330,\n","        12798,     9, 32497,   325, 16373,  2762, 21986,     9,     2,     1,\n","            1,     1,     1,     1,     1,     1,     1,     1,     1,     1])\n","mask  =  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","**********************************\n","\n","Test Data:\n","**********************************\n","Sample 1:\n","token id  =  tensor([    0,  2439,   330, 32619,   322, 23262, 29976,     9, 32497,   639,\n","          314,   451,  2045,   478,  3110,     9,     6, 21587,   312,   327,\n","        23652,  2046, 16702,     9, 12626, 11810, 35242, 10776,  1947,     9,\n","            2,     1,     1,     1,     1,     1,     1,     1,     1,     1])\n","mask  =  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","**********************************\n","Sample 2:\n","token id  =  tensor([    0,  1123,  2576,  1460,   337,   400,  6285,  1621,     9, 24141,\n","        31070,   314,  1361,   841,  8803,     9,     6,  4994,   639, 26680,\n","         1638,  8175,     9,   427,  5875,   868,  1143,  1077, 13311,     9,\n","            2,     1,     1,     1,     1,     1,     1,     1,     1,     1])\n","mask  =  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n","**********************************\n"]}],"source":["dataset =  FerdousiDataset()\n","\n","# Split into training and validation sets\n","train_size = int(0.8 * len(dataset))\n","test_size = int(0.1 * len(dataset))\n","val_size = len(dataset) - train_size - test_size\n","train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n","\n","# Create data loaders\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","print(\"len train_dataset = \",train_dataset.__len__())\n","print(\"len test_dataset = \",test_dataset.__len__())\n","\n","\n","# Print the first three samples from the train loader\n","\n","print(\"Train Data:\")\n","print(\"**********************************\")\n","beyt, mask =next(iter(train_loader))\n","for i in range(2):\n","    print(f\"Sample {i + 1}:\")\n","    print(\"token id  = \", beyt[i])\n","    print(\"mask  = \", mask[i])\n","    print(\"**********************************\")\n","\n","# Print the first three samples from the test loader\n","print(\"\\nTest Data:\")\n","print(\"**********************************\")\n","beyt, mask = next(iter(test_loader))\n","for i in range(2):\n","    print(f\"Sample {i + 1}:\")\n","    print(\"token id  = \", beyt[i])\n","    print(\"mask  = \", mask[i])\n","    print(\"**********************************\")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T20:53:06.071629Z","iopub.status.busy":"2024-01-19T20:53:06.071225Z","iopub.status.idle":"2024-01-19T20:53:09.300005Z","shell.execute_reply":"2024-01-19T20:53:09.299158Z","shell.execute_reply.started":"2024-01-19T20:53:06.071602Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"987a26074a5148538f0dc8ae7a3bf126","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/485M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Embedding(42001, 768)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["configuration = GPT2Config.from_pretrained('HooshvareLab/gpt2-fa', output_hidden_states=False)\n","model = GPT2LMHeadModel.from_pretrained(\"HooshvareLab/gpt2-fa\", config=configuration)\n","model.resize_token_embeddings(len(tokenizer))\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T20:53:09.301540Z","iopub.status.busy":"2024-01-19T20:53:09.301183Z","iopub.status.idle":"2024-01-19T20:53:09.641005Z","shell.execute_reply":"2024-01-19T20:53:09.640216Z","shell.execute_reply.started":"2024-01-19T20:53:09.301511Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)\n","\n","model.to(device)\n","\n","seed_val = 1402\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"]},{"cell_type":"markdown","metadata":{},"source":["ننظیمات زیر برای آمورش شبکه از\n","\n","https://colab.research.google.com/github/hooshvare/parsgpt/blob/master/notebooks/Persian_Poetry_FineTuning.ipynb#scrollTo=uzzFo1-zIhna\n","\n","الگوبرداری شده است"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T20:53:09.642468Z","iopub.status.busy":"2024-01-19T20:53:09.642156Z","iopub.status.idle":"2024-01-19T20:53:09.651883Z","shell.execute_reply":"2024-01-19T20:53:09.650985Z","shell.execute_reply.started":"2024-01-19T20:53:09.642441Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["warmup_steps = 1e2\n","sample_every = 300\n","epochs = 2\n","\n","from transformers import AdamW\n","\n","# AdamW is a class from the huggingface library, it is the optimizer we will be using, and we will only be instantiating it with the default parameters.\n","optimizer = AdamW(\n","    model.parameters(),\n","    lr=1e-3,\n","    eps=1e-8\n",")\n","\n","total_steps = len(train_loader) * epochs\n","\n","\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps=warmup_steps,\n","    num_training_steps=total_steps)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T20:53:09.653380Z","iopub.status.busy":"2024-01-19T20:53:09.653050Z","iopub.status.idle":"2024-01-19T20:53:09.665758Z","shell.execute_reply":"2024-01-19T20:53:09.665028Z","shell.execute_reply.started":"2024-01-19T20:53:09.653346Z"},"trusted":true},"outputs":[],"source":["def convert_token_2_beyt(token):\n","    beyt = tokenizer.decode(token, skip_special_tokens=False)\n","    beyt = beyt.replace(\"<|startoftext|>\", \"\\n\")\n","    beyt = beyt.replace(\"<s>\", \"\")\n","    beyt = beyt.replace(\"</s>\", \"\")\n","    beyt = beyt.replace(\"<pad>\", \"\")\n","    beyt = beyt.replace(\"<sep>\", \"\\n\")\n","    beyt = beyt.replace('\\n', ' ', 1).replace('\\n', '')\n","    \n","    return beyt"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T20:53:09.667644Z","iopub.status.busy":"2024-01-19T20:53:09.666810Z","iopub.status.idle":"2024-01-19T20:53:09.678171Z","shell.execute_reply":"2024-01-19T20:53:09.677505Z","shell.execute_reply.started":"2024-01-19T20:53:09.667618Z"},"trusted":true},"outputs":[],"source":["def besoray(input_txt):\n","    \n","    model.eval()\n","\n","    encodings_dict = tokenizer('<s>'  + \"<|startoftext|>\"+ input_txt + \" \" +  \"</s>\")\n","    input_id = torch.tensor(encodings_dict['input_ids'])\n","    mask = torch.tensor(encodings_dict['attention_mask'])\n","    \n","    input_id = input_id.unsqueeze(0)\n","    input_id = input_id.to(device)\n","\n","    mask = mask.unsqueeze(0)\n","    mask = mask.to(device)\n","\n","    output_id = model.generate(\n","        input_ids=input_id,\n","        do_sample=True,\n","        top_k=50,\n","        max_length=40, \n","        top_p=0.95,\n","        num_return_sequences=1,\n","        attention_mask = mask\n","    )\n","\n","    generated_beyt = convert_token_2_beyt(output_id[0])\n","    \n","    return generated_beyt"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T20:53:09.679503Z","iopub.status.busy":"2024-01-19T20:53:09.679199Z","iopub.status.idle":"2024-01-19T21:00:22.482677Z","shell.execute_reply":"2024-01-19T21:00:22.481659Z","shell.execute_reply.started":"2024-01-19T20:53:09.679477Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch: 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 621/621 [03:23<00:00,  3.06it/s]\n","Setting `pad_token_id` to `eos_token_id`:5 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Average Training Loss: 3.55961382523443\n","\n","Example input: میازار موری که دانه کش است\n","Example output:  میازار موری که دانه کش است به کار اندرش مغز و تن آدمیستخردمند بود از کران تا کرانهمی رای زد بر یکی سرو کوه\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 78/78 [00:08<00:00,  9.67it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Validation loss: 2.9062254214898133\n","\n","epoch: 1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 621/621 [03:30<00:00,  2.95it/s]\n","Setting `pad_token_id` to `eos_token_id`:5 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Average Training Loss: 2.517018845307846\n","\n","Example input: میازار موری که دانه کش است\n","Example output:  میازار موری که دانه کش است بنه بر چمنها و آب و خاک استدرخت و گیا جای و بالای او\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 78/78 [00:08<00:00,  9.66it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Validation loss: 2.662956552627759\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["for epoch_i in range(0, epochs):\n","\n","    print(f'epoch: {epoch_i}')\n","\n","    total_train_loss = 0\n","\n","    model.train()\n","\n","    for step, (beyt, mask) in tqdm(enumerate(train_loader), total=len(train_loader), position=0):\n","\n","        beyt = beyt.to(device)\n","        mask = mask.to(device)\n","\n","        model.zero_grad()\n","\n","        outputs = model(beyt, labels=beyt, attention_mask=mask, token_type_ids=None)\n","\n","        loss = outputs[0]\n","\n","        batch_loss = loss.item()\n","        total_train_loss += batch_loss\n","\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","    avg_train_loss = total_train_loss / len(train_loader)\n","\n","\n","    print(f'\\nAverage Training Loss: {avg_train_loss}\\n')\n","    \n","    model.eval()\n","    sample_beyt = \"میازار موری که دانه کش است\"\n","    print(f'Example input:',sample_beyt)\n","    gen_sample_output = besoray(sample_beyt)\n","    print(f'Example output: {gen_sample_output}')\n","\n","\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for beyt, mask in tqdm(val_loader, total=len(val_loader), position=0):\n","\n","        beyt = beyt.to(device)\n","        mask = mask.to(device)\n","\n","        with torch.no_grad():\n","\n","            outputs = model(beyt, labels=beyt, attention_mask=mask, token_type_ids=None)\n","\n","            loss = outputs[0]\n","\n","        batch_loss = loss.item()\n","        total_eval_loss += batch_loss\n","\n","    avg_val_loss = total_eval_loss / len(val_loader)\n","\n","    print(f'\\nValidation loss: {avg_val_loss}\\n')"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T21:00:22.484339Z","iopub.status.busy":"2024-01-19T21:00:22.484030Z","iopub.status.idle":"2024-01-19T21:00:23.073010Z","shell.execute_reply":"2024-01-19T21:00:23.072204Z","shell.execute_reply.started":"2024-01-19T21:00:22.484313Z"},"trusted":true},"outputs":[],"source":["model_path = 'HW4_Q3_model.pth'\n","torch.save(model.state_dict(), model_path)"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T21:13:38.266720Z","iopub.status.busy":"2024-01-19T21:13:38.266306Z","iopub.status.idle":"2024-01-19T21:13:38.628071Z","shell.execute_reply":"2024-01-19T21:13:38.627122Z","shell.execute_reply.started":"2024-01-19T21:13:38.266693Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:5 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" بدو گفت رستم که که نام تو چیست ازو چار چیزست و کام تو چیستکدامست با نام تو چیست\n"]}],"source":["print(besoray(\"بدو گفت رستم که که نام تو چیست\"))"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T21:06:28.005947Z","iopub.status.busy":"2024-01-19T21:06:28.005203Z","iopub.status.idle":"2024-01-19T21:06:28.413079Z","shell.execute_reply":"2024-01-19T21:06:28.412180Z","shell.execute_reply.started":"2024-01-19T21:06:28.005915Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:5 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" چنین گفت رستم به اسفندیار که ای تاجور خسرو نامدارمن این پور دستان شیرگیرسرآید شما را بدین مرز دار\n"]}],"source":["print(besoray(\"چنین گفت رستم به اسفندیار\"))"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T19:07:37.305396Z","iopub.status.busy":"2024-01-19T19:07:37.304714Z","iopub.status.idle":"2024-01-19T19:07:37.711005Z","shell.execute_reply":"2024-01-19T19:07:37.709980Z","shell.execute_reply.started":"2024-01-19T19:07:37.305364Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:5 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" یکی روبهی بود بی دست که با جنگ ایشان نیایدت ننگبکردار دریا و دریا نمودهمان جنگشان جنگ را دست سود\n"]}],"source":["print(besoray(\"یکی روبهی بود بی دست\"))"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T19:08:35.005323Z","iopub.status.busy":"2024-01-19T19:08:35.004490Z","iopub.status.idle":"2024-01-19T19:08:35.460103Z","shell.execute_reply":"2024-01-19T19:08:35.459062Z","shell.execute_reply.started":"2024-01-19T19:08:35.005289Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:5 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" به نام خداوند خداوند بخشنده و پاک تنخداوند نیکی دهش باد\n"]}],"source":["print(besoray(\"به نام خداوند\"))"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T19:10:33.399922Z","iopub.status.busy":"2024-01-19T19:10:33.398845Z","iopub.status.idle":"2024-01-19T19:10:33.845278Z","shell.execute_reply":"2024-01-19T19:10:33.844237Z","shell.execute_reply.started":"2024-01-19T19:10:33.399883Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:5 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" که تمرین دیپ گرامی و راد و فرهنگ و رایبه نیروی یزدان دلیران به پای\n"]}],"source":["print(besoray(\"که تمرین دیپ\"))"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T19:51:18.053019Z","iopub.status.busy":"2024-01-19T19:51:18.052615Z","iopub.status.idle":"2024-01-19T19:51:18.450753Z","shell.execute_reply":"2024-01-19T19:51:18.449855Z","shell.execute_reply.started":"2024-01-19T19:51:18.052990Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:5 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" که هنگ کنگ ما را نه مردی بکین و نه نام و ننگنگفتی تو در چنگ مردی پلنگ\n"]}],"source":["print(besoray(\"که هنگ کنگ ما را\"))"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4263625,"sourceId":7342980,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
